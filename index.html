<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Structure Agnostic Video Editing (SAVE) generates natural videos, replacing the protagonist of a source video while preserving the motion.">
  <meta name="keywords" content="Diffusion, Video Editing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SAVE: Protagonist Diversification with Structure Agnostic Video Editing</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SAVE: Protagonist Diversification with <span style="text-decoration : underline;">S</span>tructure <span style="text-decoration : underline;">A</span>gnostic <span style="text-decoration : underline;">V</span>ideo <span style="text-decoration : underline;">E</span>diting</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://keunhong.com">Yeji Song</a><sup>1</sup>,</span>
            <span class="author-block">
              Wonsik Shin<sup>1</sup>,</span>
            <span class="author-block">
              Junsoo Lee<sup>2</sup>,
            </span>
            <span class="author-block">
              Jeesoo Kim<sup>2</sup>,
            </span>
            <span class="author-block">
              Nojun Kwak<sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Seoul National University,</span>
            <span class="author-block"><sup>2</sup>Webtoon AI</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ldynx/SAVE"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <!-- Cat-in-the-sun -->
        <div class="item item-cat-sun">
          <div>
            <video poster="" id="pikachu-sun" autoplay controls muted loop playsinline height="90%">
              <source src="./static/videos/cat_in_the_sun/Ours_Pikachu.mp4"
                      type="video/mp4">
            </video>
          </div>
          <br />
          <div>
              <div onclick="toggle_prompt('./static/videos/cat_in_the_sun/Ours_Pikachu.mp4', ['./static/videos/cat_in_the_sun/Ours_dog.mp4', './static/videos/cat_in_the_sun/Ours_tiger.mp4'], 'cat-sun-result')" class="caption caption-active" id="cat-sun-pikachu">"Pikachu is S<sub>mot</sub> in the grass in the sun"</div>
              <br />
              <div onclick="toggle_prompt('./static/videos/cat_in_the_sun/Ours_dog.mp4', ['./static/videos/cat_in_the_sun/Ours_Pikachu.mp4', './static/videos/cat_in_the_sun/Ours_tiger.mp4'], 'cat-sun-result')" class="caption" id="cat-sun-dog">"a dog is S<sub>mot</sub> in the grass in the sun"</div>
              <br />
              <div onclick="toggle_prompt('./static/videos/cat_in_the_sun/Ours_tiger.mp4', ['./static/videos/cat_in_the_sun/Ours_dog.mp4', './static/videos/cat_in_the_sun/Ours_Pikachu.mp4'], 'cat-sun-result')" class="caption" id="cat-sun-tiger">"a tiger is S<sub>mot</sub> in the grass in the sun"</div>
          </div>
        </div>

        <!--
        <div class="item item-cat-flower">
          <video poster="" id="cat-flower" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/cat_flower/cat.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-cat-flower">
          <video poster="" id="dog-flower" autoplay controls muted loop playsinline height="90%">
            <source src="./static/videos/cat_flower/Ours.mp4"
                    type="video/mp4">
          </video>
        </div>
        -->
        
      </div>
    </div>
  </div>
</section>

  
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Previous works usually work well on trivial and consistent shapes, and easily collapse on
            a difficult target that has a largely different body shape from
            the original one. In this paper, we spot the bias problem in
            the existing video editing method that restricts the range
            of choices for the new protagonist and attempt to address
            this issue using the conventional image-level personalization method. 
            <span style=" background: linear-gradient(to top, #F8D32D 50%, transparent 50%)">We adopt 
            motion personalization that isolates the motion from a single source video and then modifies the
            protagonist accordingly.</span> To deal with the natural discrepancy 
            between image and video, we propose a motion word
            with an <span style=" background: linear-gradient(to top, #67D1E1 50%, transparent 50%)">inflated textual embedding<sup>1</sup></span> 
            to properly represent the motion in a source video. We also regulate the motion word
            to attend to proper motion-related areas by introducing a
            <span style=" background: linear-gradient(to top, #67D1E1 50%, transparent 50%)">novel pseudo optical flow<sup>2</sup></span>,
            efficiently computed from the pre-calculated attention maps. Finally, we decouple the motion
            from the appearance of the source video with an 
            <span style=" background: linear-gradient(to top, #67D1E1 50%, transparent 50%)">additional pseudo word<sup>3</sup></span>. 
            Extensive experiments demonstrate the editing capability of our method, 
            taking a step toward more diverse and extensive video editing.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <h2 class="title is-3">Method</h2>
      <br/>
      <!-- Inflated Text Embedding. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Inflated Text Embedding<sup>1</sup></h2>
          <p>
            We expand the textual embedding space of a motion word to represent a time 
            flow in videos rather than a frozen moment in images: we add a temporal axis to an embedding space
            of our new motion word <span style="font-family: 'Cambria Math';">S<sub>mot</sub></span> and 
            let <span style="font-family: 'Cambria Math';">S<sub>mot</sub></span> inject its information into a proper region in each frame.
          </p>
          <h2 class="title is-4">Pre-registration Strategy<sup>3</sup></h2>
          <p>
            The motion and the protagonist get easily entangled. To resolve this problem, we propose a two-stage
            training strategy to untangle the two properties. We newly define a pseudo-word
            <span style="font-family: 'Cambria Math';">S<sub>pro</sub></span> that represents the appearance and 
            texture features of the protagonist. As the protagonist and its appearances are already registered 
            in the text encoder, <span style="font-family: 'Cambria Math';">S<sub>mot</sub></span> can be effectively
            learned using disentangled motion information for the video.
          </p>
        </div>
      </div>
      <!--/ Inflated Text Embedding. -->

      <!-- Pseudo Optical Flow. -->
      <div class="column">
        <h2 class="title is-4">Pseudo Optical Flow<sup>2</sup></h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Our intuition lies on that if the <span style="font-family: 'Cambria Math';">k</span>-th pixel of the 
              <span style="font-family: 'Cambria Math';">i</span>-th frame and the 
              <span style="font-family: 'Cambria Math';">l</span>-th pixel of the 
              <span style="font-family: 'Cambria Math';">j</span>-th frame 
              have a high spatio-temporal attention score, then they tend to be the same semantic point at different frames. 
              Therefore, by tracking down spatial locations of these similar points across frames, we can estimate the
              temporal flow of each pixel in the video. We introduce a novel pseudo optical flow to represent better 
              the moving area without using the costly optical flow models and enabling <span style="font-family: 'Cambria Math';">S<sub>mot</sub></span>
              to focus on the movement.
            </p>
            <img src="./static/images/Method_motion_map.png">
            </video>
          </div>

        </div>
      </div>
      <!--/ Pseudo Optical Flow. -->
    </div>

    <br/>
    <!-- Comparison -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Comparison</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Comparison -->


    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
